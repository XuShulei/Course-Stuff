diff -Naur ./linux-2.6.9-default/arch/i386/kernel/entry.S ./linux-2.6.9-lab4/arch/i386/kernel/entry.S
--- ./linux-2.6.9-default/arch/i386/kernel/entry.S	2004-10-18 17:53:44.000000000 -0400
+++ ./linux-2.6.9-lab4/arch/i386/kernel/entry.S	2017-10-14 16:35:18.000000000 -0400
@@ -901,5 +901,5 @@
 	.long sys_mq_getsetattr
 	.long sys_ni_syscall		/* reserved for kexec */
 	.long sys_waitid
-
+	.long sys_cp_range /* 285 */
 syscall_table_size=(.-sys_call_table)
diff -Naur ./linux-2.6.9-default/include/asm-i386/unistd.h ./linux-2.6.9-lab4/include/asm-i386/unistd.h
--- ./linux-2.6.9-default/include/asm-i386/unistd.h	2004-10-18 17:54:37.000000000 -0400
+++ ./linux-2.6.9-lab4/include/asm-i386/unistd.h	2017-10-28 04:00:24.000000000 -0400
@@ -290,8 +290,9 @@
 #define __NR_mq_getsetattr	(__NR_mq_open+5)
 #define __NR_sys_kexec_load	283
 #define __NR_waitid		284
+#define __NR_cp_range	285
 
-#define NR_syscalls 285
+#define NR_syscalls 286
 
 /* user-visible error numbers are in the range -1 - -124: see <asm-i386/errno.h> */
 
@@ -444,7 +445,6 @@
 				const struct sigaction __user *act,
 				struct sigaction __user *oact,
 				size_t sigsetsize);
-
 #endif
 
 /*
diff -Naur ./linux-2.6.9-default/include/linux/mm.h ./linux-2.6.9-lab4/include/linux/mm.h
--- ./linux-2.6.9-default/include/linux/mm.h	2004-10-18 17:53:07.000000000 -0400
+++ ./linux-2.6.9-lab4/include/linux/mm.h	2017-11-02 04:33:02.000000000 -0400
@@ -235,6 +235,11 @@
 	void *virtual;			/* Kernel virtual address (NULL if
 					   not kmapped, ie. highmem) */
 #endif /* WANT_PAGE_VIRTUAL */
+        unsigned int cp_flag; 
+                                /* this flag indicates whether this page has been checkpointed or not
+                                    1: checkpointed - do checkpoint if and only if this page is dirty
+                                    0: not yet - need to do checkpoint  (default) */
+        unsigned int checksum;
 };
 
 /*
diff -Naur ./linux-2.6.9-default/include/linux/syscalls.h ./linux-2.6.9-lab4/include/linux/syscalls.h
--- ./linux-2.6.9-default/include/linux/syscalls.h	2004-10-18 17:55:36.000000000 -0400
+++ ./linux-2.6.9-lab4/include/linux/syscalls.h	2017-10-31 15:58:10.000000000 -0400
@@ -491,4 +491,6 @@
 asmlinkage long sys_uselib(const char __user *library);
 asmlinkage long sys_ni_syscall(void);
 
+asmlinkage int sys_cp_range(void *start_addr, void *end_addr, int use_incr_cp);
+
 #endif
diff -Naur ./linux-2.6.9-default/kernel/cp_range.c ./linux-2.6.9-lab4/kernel/cp_range.c
--- ./linux-2.6.9-default/kernel/cp_range.c	1969-12-31 19:00:00.000000000 -0500
+++ ./linux-2.6.9-lab4/kernel/cp_range.c	2017-11-03 14:32:01.000000000 -0400
@@ -0,0 +1,317 @@
+#include <linux/unistd.h>
+#include <linux/linkage.h>
+#include <linux/fs.h>
+#include <asm/segment.h>
+#include <asm/uaccess.h>
+#include <linux/buffer_head.h>
+#include <linux/fcntl.h>
+#include <linux/sched.h>
+#include <asm/checksum.h>
+#include <linux/mm.h>
+
+/* Functions to write to files. Influenced heavily by stack overflow post */
+struct file *file_open(const char *path, int flags, int rights) {
+    struct file *f = NULL;
+    // Swap the memory segments because we can't write files in kernel space
+    mm_segment_t oldfs;
+    int err = 0;
+    
+    oldfs = get_fs();
+    set_fs(get_ds());
+    f = filp_open(path, flags, rights);
+    set_fs(oldfs);
+
+    // Check for errors, return null if error
+    if (IS_ERR(f)) {
+        err = PTR_ERR(f);
+        return NULL;
+    }
+    return f;
+}
+
+/* Close the file pointer */
+void file_close(struct file *file) {
+    filp_close(file, NULL);
+}
+
+/* write data to file */
+int file_write(struct file *file, unsigned long long offset, unsigned char *data, 
+unsigned int size) {
+    mm_segment_t oldfs;
+    int ret;
+
+    // swap fs so we can write to disk
+    oldfs = get_fs();
+    set_fs(get_ds());
+
+    ret = vfs_write(file, data, size, &offset);
+
+    // Return to previous state
+    set_fs(oldfs);
+    return ret;
+}
+
+
+#include <linux/mm.h>
+#include <linux/hugetlb.h>
+#include <linux/pagemap.h>
+#include <linux/page-flags.h>
+#include <asm-i386/cacheflush.h>
+
+
+/* defined mm/memory.c */
+static inline struct page *get_page_map(struct page *page)
+{
+	if (!pfn_valid(page_to_pfn(page)))
+		return NULL;
+	return page;
+}
+static inline int
+untouched_anonymous_page(struct mm_struct* mm, struct vm_area_struct *vma,
+			 unsigned long address)
+{
+	pgd_t *pgd;
+	pmd_t *pmd;
+
+	/* Check if the vma is for an anonymous mapping. */
+	if (vma->vm_ops && vma->vm_ops->nopage)
+		return 0;
+
+	/* Check if page directory entry exists. */
+	pgd = pgd_offset(mm, address);
+	if (pgd_none(*pgd) || unlikely(pgd_bad(*pgd)))
+		return 1;
+
+	/* Check if page middle directory entry exists. */
+	pmd = pmd_offset(pgd, address);
+	if (pmd_none(*pmd) || unlikely(pmd_bad(*pmd)))
+		return 1;
+
+	/* There is a pte slot for 'address' in 'mm'. */
+	return 0;
+}
+extern int handle_mm_fault(struct mm_struct *mm, struct vm_area_struct * vma,
+	unsigned long address, int write_access);
+
+/* Based on get_user_pages(...), we wrote this modified version to
+ * have different handles while walking through VMAs and pages */
+int my_get_user_page(struct task_struct *tsk, struct mm_struct *mm,
+                unsigned long start, int len, int write, int force,
+                struct page **pages, struct vm_area_struct **vmas,
+                int use_incr_cp)
+{
+    int i = 0;
+
+    do {
+            struct vm_area_struct * vma;
+
+            printk("[%s] Finding VMA for mm %p, start %x\n", __FUNCTION__, mm, start);
+
+            vma = find_extend_vma(mm, start);
+
+            if (!vma && in_gate_area(tsk, start)) {
+                    unsigned long pg = start & PAGE_MASK;
+                    struct vm_area_struct *gate_vma = get_gate_vma(tsk);
+                    pgd_t *pgd;
+                    pmd_t *pmd;
+                    pte_t *pte;
+                    if (write) /* user gate pages are read-only */
+                            return i ? : -EFAULT;
+                    pgd = pgd_offset_gate(mm, pg);
+                    if (!pgd)
+                            return i ? : -EFAULT;
+                    pmd = pmd_offset(pgd, pg);
+                    if (!pmd)
+                            return i ? : -EFAULT;
+                    pte = pte_offset_map(pmd, pg);
+                    if (!pte)
+                            return i ? : -EFAULT;
+                    if (!pte_present(*pte)) {
+                            pte_unmap(pte);
+                            return i ? : -EFAULT;
+                    }
+                    if (pte_none(*pte)) {
+                        printk("[%s] pte_none is true\n", __FUNCTION__);
+                        pte_unmap(pte);
+                        return i ? : -EFAULT;
+                    }
+                    if (pages) {
+                            pages[i] = pte_page(*pte);
+                            get_page(pages[i]);
+                    }
+                    pte_unmap(pte);
+                    if (vmas)
+                            vmas[i] = gate_vma;
+                    i++;
+                    start += PAGE_SIZE;
+                    len--;
+                    continue;
+            }
+
+            /* Return NULL if VMA is not found or
+                if incremental design is enabled, ignore VMA with VM_IO flag */
+            if (!vma || (use_incr_cp && pages && (vma->vm_flags & VM_IO))) {
+                    return i ? : -EFAULT;
+            }
+            /* VMA is found */
+
+            if (is_vm_hugetlb_page(vma)) {
+                    i = follow_hugetlb_page(mm, vma, pages, vmas,
+                                            &start, &len, i);
+                    continue;
+            }
+            spin_lock(&mm->page_table_lock);
+            do {
+                    struct page *map;
+                    int lookup_write = 0;
+                    while (!(map = follow_page(mm, start, lookup_write))) {
+                            /*
+                             * Shortcut for anonymous pages. We don't want
+                             * to force the creation of pages tables for
+                             * insanly big anonymously mapped areas that
+                             * nobody touched so far. This is important
+                             * for doing a core dump for these mappings.
+                             */
+
+                            if (use_incr_cp && !lookup_write &&
+                                untouched_anonymous_page(mm,vma,start)) {
+                                    map = ZERO_PAGE(start);
+                                    break;
+                            }
+                            
+                            spin_unlock(&mm->page_table_lock);
+                            
+                            switch (handle_mm_fault(mm,vma,start,write)) {
+                            case VM_FAULT_MINOR:
+                                    tsk->min_flt++;
+                                    break;
+                            case VM_FAULT_MAJOR:
+                                    tsk->maj_flt++;
+                                    break;
+                            case VM_FAULT_SIGBUS:
+                                    return i ? i : -EFAULT;
+                            case VM_FAULT_OOM:
+                                    return i ? i : -ENOMEM;
+                            default:
+                                    BUG();
+                            }
+                            spin_lock(&mm->page_table_lock);
+                    }
+                    if (pages) {
+                            pages[i] = get_page_map(map);
+                            if (!pages[i]) {
+                                    spin_unlock(&mm->page_table_lock);
+                                    while (i--)
+                                            page_cache_release(pages[i]);
+                                    printk("[%s] No page found %p\n", __FUNCTION__, pages[i]);
+                                    i = -EFAULT;
+                                    goto out;
+                            }
+                            flush_dcache_page(pages[i]);
+                            if (!PageReserved(pages[i]))
+                                    page_cache_get(pages[i]);
+                    }
+                    if (vmas)
+                            vmas[i] = vma;
+                    i++;
+                    start += PAGE_SIZE;
+                    len--;
+            } while(len && start < vma->vm_end);
+            spin_unlock(&mm->page_table_lock);
+    } while(len);
+out:
+    return i;
+}
+
+unsigned int count = 0;
+unsigned int incr_cp_count = 0;
+
+asmlinkage int sys_cp_range(void *start_addr, void *end_addr, int use_incr_cp) {
+
+    if ((unsigned long)end_addr > 0xBFFFFFFF)
+        end_addr = (void *) 0xBFFFFFFF;
+
+    unsigned long num_bytes = (unsigned long) end_addr - (unsigned long) 
+start_addr;
+    /* First check the buffer is within user space */
+    if (0 == access_ok(VERIFY_READ, start_addr, num_bytes))
+        return -1;  /* Meaning failed to access the given buffer since it is not within user space */
+
+    printk("[%s] System call cp_range invoked with use_incr_cp = %d\n", __FUNCTION__, use_incr_cp);
+
+    /* Write to a fixed directory, using count to separate them */
+    char fname[40];
+    if (use_incr_cp)
+        sprintf(fname, "/root/lab4/cp_files/incr_cp_%d", incr_cp_count);
+    else
+        sprintf(fname, "/root/lab4/cp_files/cp_%d", count);
+    printk("[%s] to write cp content to file %s\n", __FUNCTION__, fname);
+    struct file *filp = file_open(fname, O_WRONLY|O_CREAT, 0);
+
+    /* Use example from access_proces_vm() in ptrace.c to write memory to file 
+     * or should implement one by ourselves? */
+    struct page *page;
+    struct vm_area_struct *vma;
+
+    int write = 0;
+    unsigned int write_offset = 0;
+    void *addr = start_addr;
+    void *pBuff;
+    unsigned int temp_checksum;
+    int need_write = 1;
+
+    pBuff = kmalloc(PAGE_SIZE, GFP_KERNEL);
+
+    while (num_bytes > 0) {
+        int bytes = 0, ret, offset = 0;
+        void *maddr;
+        
+        ret = my_get_user_page(current, current->active_mm, (unsigned long) addr, 1, write, 0, &page, &vma, use_incr_cp);
+        
+        if (-14 == ret || 0 == ret) {
+            num_bytes -= PAGE_SIZE;
+            addr += PAGE_SIZE;
+            printk("[%s] No page found, checking next page\n", __FUNCTION__);
+        }
+        else if (ret < 0) {
+            // get_user_pages() is returning -14 (EFAULT, bad address) when the	addr is	0.
+            printk("[%s] Error getting user pages. Error code %d\n", __FUNCTION__, ret);
+            return -1;
+        } else {
+            if (empty_zero_page != page) {
+                bytes = num_bytes;
+                offset = (unsigned long)addr & (PAGE_SIZE - 1);
+                if (bytes > PAGE_SIZE-offset)
+                   bytes = PAGE_SIZE-offset;
+
+                maddr = kmap(page);
+
+                /* Check checksum if incremental is enabled */
+                if (use_incr_cp == 1)
+                {
+                    copy_from_user_page(vma, page, start_addr, pBuff, maddr, PAGE_SIZE);
+                    temp_checksum = csum_partial(pBuff, PAGE_SIZE, 0);
+                    printk("[%s] old checksum %u new checksum %u\n", __FUNCTION__, page->checksum, temp_checksum);
+                    if (page->checksum != temp_checksum)
+                        need_write = 0;
+                    page->checksum = temp_checksum;
+                    page->cp_flag = 1;
+                }
+
+                /* Save the content if
+                    1) using basic cp scheme
+                    2) using incremental design and the page is dirty */
+                if (need_write) {
+                    file_write(filp, write_offset, maddr + offset, bytes);
+                    write_offset += bytes;
+                } else
+                    printk("[%s] page hasn't been modified\n", __FUNCTION__);
+            } else
+                printk("[%s] got a zero page, just igonore\n", __FUNCTION__);
+            num_bytes -= bytes;
+            addr += bytes;
+        }    
+    }
+
+    return (use_incr_cp) ? incr_cp_count++ : count++; /* Use return value to know which file we should look at after */
+}
diff -Naur ./linux-2.6.9-default/kernel/Makefile ./linux-2.6.9-lab4/kernel/Makefile
--- ./linux-2.6.9-default/kernel/Makefile	2004-10-18 17:53:43.000000000 -0400
+++ ./linux-2.6.9-lab4/kernel/Makefile	2017-10-26 04:03:50.000000000 -0400
@@ -7,7 +7,7 @@
 	    sysctl.o capability.o ptrace.o timer.o user.o \
 	    signal.o sys.o kmod.o workqueue.o pid.o \
 	    rcupdate.o intermodule.o extable.o params.o posix-timers.o \
-	    kthread.o
+	    kthread.o cp_range.o
 
 obj-$(CONFIG_FUTEX) += futex.o
 obj-$(CONFIG_GENERIC_ISA_DMA) += dma.o
diff -Naur ./linux-2.6.9-default/Makefile ./linux-2.6.9-lab4/Makefile
--- ./linux-2.6.9-default/Makefile	2004-10-18 17:54:38.000000000 -0400
+++ ./linux-2.6.9-lab4/Makefile	2017-10-28 03:37:52.000000000 -0400
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 6
 SUBLEVEL = 9
-EXTRAVERSION =
+EXTRAVERSION = lab4
 NAME=Zonked Quokka
 
 # *DOCUMENTATION*
